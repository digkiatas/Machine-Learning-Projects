{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
   "metadata": {},
   "source": [
    "![Credit card being held in hand](credit_card.jpg)\n",
    "\n",
    "Commercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n",
    "\n",
    "### The Data\n",
    "\n",
    "The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4451,
    "lastExecutedAt": 1717667975217,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt",
    "outputsMetadata": {
     "0": {
      "height": 196,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74a3d38-9185-4111-8bc8-640351dd917c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 58,
    "lastExecutedAt": 1717667975277,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header = None) \ncc_apps.head()",
    "outputsMetadata": {
     "0": {
      "height": 194,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>g</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>g</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header = None) \n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f180fb88-7e2e-4d53-b930-bdfa78b6d066",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1717667975329,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# EDA for missing values and feature categories\n\n# Better way to detect missing values\ncolumns = cc_apps.columns\nfor column in columns:\n    print(cc_apps[column].unique())",
    "outputsMetadata": {
     "0": {
      "height": 555,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b' 'a' '?']\n",
      "['30.83' '58.67' '24.50' '27.83' '20.17' '32.08' '33.17' '22.92' '54.42'\n",
      " '42.50' '22.08' '29.92' '38.25' '48.08' '45.83' '36.67' '28.25' '23.25'\n",
      " '21.83' '19.17' '25.00' '47.75' '27.42' '41.17' '15.83' '47.00' '56.58'\n",
      " '57.42' '42.08' '29.25' '42.00' '49.50' '36.75' '22.58' '27.25' '23.00'\n",
      " '27.75' '54.58' '34.17' '28.92' '29.67' '39.58' '56.42' '54.33' '41.00'\n",
      " '31.92' '41.50' '23.92' '25.75' '26.00' '37.42' '34.92' '34.25' '23.33'\n",
      " '23.17' '44.33' '35.17' '43.25' '56.75' '31.67' '23.42' '20.42' '26.67'\n",
      " '36.00' '25.50' '19.42' '32.33' '34.83' '38.58' '44.25' '44.83' '20.67'\n",
      " '34.08' '21.67' '21.50' '49.58' '27.67' '39.83' '?' '37.17' '25.67'\n",
      " '34.00' '49.00' '62.50' '31.42' '52.33' '28.75' '28.58' '22.50' '28.50'\n",
      " '37.50' '35.25' '18.67' '54.83' '40.92' '19.75' '29.17' '24.58' '33.75'\n",
      " '25.42' '37.75' '52.50' '57.83' '20.75' '39.92' '24.75' '44.17' '23.50'\n",
      " '47.67' '22.75' '34.42' '28.42' '67.75' '47.42' '36.25' '32.67' '48.58'\n",
      " '33.58' '18.83' '26.92' '31.25' '56.50' '43.00' '22.33' '32.83' '40.33'\n",
      " '30.50' '52.83' '46.67' '58.33' '37.33' '23.08' '32.75' '68.67' '28.00'\n",
      " '44.00' '25.08' '32.00' '60.58' '40.83' '19.33' '41.33' '56.00' '49.83'\n",
      " '22.67' '27.00' '26.08' '18.42' '21.25' '57.08' '22.42' '48.75' '40.00'\n",
      " '40.58' '28.67' '33.08' '21.33' '41.75' '34.50' '48.17' '27.58' '24.08'\n",
      " '24.83' '36.33' '35.42' '71.58' '39.50' '39.33' '24.33' '60.08' '55.92'\n",
      " '53.92' '18.92' '50.08' '65.42' '17.58' '18.08' '19.67' '25.17' '33.50'\n",
      " '58.42' '26.17' '42.83' '38.17' '20.50' '48.25' '28.33' '18.75' '18.50'\n",
      " '45.00' '40.25' '41.42' '17.83' '18.17' '20.00' '52.17' '50.75' '17.08'\n",
      " '18.33' '59.67' '18.00' '37.58' '30.67' '18.58' '16.25' '21.17' '17.67'\n",
      " '16.50' '29.50' '21.75' '18.25' '35.75' '16.08' '69.17' '32.92' '16.33'\n",
      " '22.17' '57.58' '15.92' '31.75' '19.00' '17.50' '33.67' '30.17' '33.25'\n",
      " '25.25' '34.75' '47.33' '39.08' '42.75' '38.92' '62.75' '32.25' '26.75'\n",
      " '63.33' '30.75' '16.00' '19.50' '32.42' '30.25' '26.83' '16.92' '24.42'\n",
      " '39.42' '23.58' '21.42' '33.00' '26.33' '26.25' '28.17' '20.83' '43.17'\n",
      " '56.83' '15.17' '29.83' '31.00' '51.92' '69.50' '19.58' '22.25' '38.42'\n",
      " '26.58' '35.00' '29.42' '49.17' '51.83' '58.58' '53.33' '27.17' '25.92'\n",
      " '30.58' '17.25' '27.33' '36.50' '29.75' '52.42' '36.17' '34.58' '21.92'\n",
      " '36.58' '31.08' '30.42' '21.08' '17.42' '39.17' '26.50' '17.33' '23.75'\n",
      " '34.67' '74.83' '45.33' '47.25' '24.17' '39.25' '39.00' '64.08' '31.33'\n",
      " '21.00' '13.75' '46.00' '20.25' '60.92' '30.00' '22.83' '45.17' '41.58'\n",
      " '55.75' '25.33' '31.83' '33.92' '24.92' '80.25' '30.08' '48.33' '76.75'\n",
      " '51.33' '41.92' '29.58' '32.17' '51.42' '42.17' '43.08' '59.50' '65.17'\n",
      " '20.33' '48.50' '28.08' '73.42' '51.58' '38.67' '46.08' '20.08' '42.25'\n",
      " '16.17' '47.83' '22.00' '38.33' '25.58' '21.58' '36.08' '38.75' '35.58'\n",
      " '31.58' '15.75' '17.92' '30.33' '47.17' '25.83' '50.25' '36.42']\n",
      "[ 0.     4.46   0.5    1.54   5.625  4.     1.04  11.585  4.915  0.83\n",
      "  1.835  6.     6.04  10.5    4.415  0.875  5.875  0.25   8.585 11.25\n",
      "  1.     8.    14.5    6.5    0.585 13.    18.5    8.5   14.79   9.79\n",
      "  7.585  5.125 10.75   1.5    1.585 11.75   9.415  9.17  15.     1.415\n",
      " 13.915 28.     6.75   2.04   0.665  2.5    3.    11.625  4.5   12.25\n",
      " 16.165  0.79   0.835  4.25   0.375 25.125  7.5    5.     7.     5.29\n",
      "  1.165  9.75  19.     3.5    0.625  2.21  12.75  15.5    1.375  3.54\n",
      " 11.     1.75  16.5   12.     2.25   0.75  12.5    1.25   1.125  7.04\n",
      " 10.335  6.21   6.665  9.     5.5    0.54   2.75   9.5   13.5    3.75\n",
      " 16.     0.29   1.665  7.54   0.46  10.    11.5    3.04   2.     0.08\n",
      "  1.71   3.25   2.54  13.585  8.665  9.25   8.17   2.335 19.5    5.665\n",
      "  4.625  0.205  0.96   4.04   5.04   3.165  7.625 10.04  10.25   2.125\n",
      "  9.335  6.625  2.71   9.625 12.54   9.54   8.46  13.75  21.    10.125\n",
      " 25.085  0.21  21.5   11.125 11.045  1.335  0.085  1.21   0.165  5.71\n",
      "  5.415 12.625  0.58   0.415  2.415  0.335  3.125 12.125  2.875 13.665\n",
      " 26.335 10.29   1.29  22.     0.125  1.085  4.085  4.71   6.165  4.585\n",
      " 11.46  14.585  0.17   1.625  2.085  5.085  8.125  2.835  1.79   0.705\n",
      "  2.165  2.29  18.125  3.085 11.665  4.125  1.08  13.335 11.835  4.79\n",
      "  9.96   7.08  25.21   0.67   3.79  22.29   3.335  0.42   1.46   0.04\n",
      " 12.33  12.335  0.915 14.    17.75  20.     5.25   4.165 10.915  4.75\n",
      " 10.415  7.835  0.71   2.46   9.585  3.625  2.665  5.835 12.835 10.665\n",
      "  7.25  10.21   3.29  10.085  3.375]\n",
      "['u' 'y' '?' 'l']\n",
      "['g' 'p' '?' 'gg']\n",
      "['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j' '?']\n",
      "['v' 'h' 'bb' 'ff' 'j' 'z' '?' 'o' 'dd' 'n']\n",
      "[ 1.25   3.04   1.5    3.75   1.71   2.5    6.5    0.04   3.96   3.165\n",
      "  2.165  4.335  1.     5.     0.25   0.96   3.17   0.665  0.75   0.835\n",
      "  7.875  3.085  0.5    5.165 15.     7.     5.04   7.96   7.585  0.415\n",
      "  2.     1.835 14.415  4.5    5.335  8.625 28.5    2.625  0.125  6.04\n",
      "  3.5    0.165  0.875  1.75   0.     7.415  0.085  5.75   6.     3.\n",
      "  1.585  4.29   1.54   1.46   1.625 12.5   13.5   10.75   0.375  0.585\n",
      "  0.455  4.     8.5    9.46   2.25  10.     0.795  1.375  1.29  11.5\n",
      "  6.29  14.     0.335  1.21   7.375  7.5    3.25  13.     5.5    4.25\n",
      "  0.625  5.085  2.75   2.375  8.     1.085  2.54   4.165  1.665 11.\n",
      "  9.     1.335  1.415  1.96   2.585  5.125 15.5    0.71   5.665 18.\n",
      "  5.25   8.665  2.29  20.     2.46  13.875  2.085  4.58   2.71   2.04\n",
      "  0.29   4.75   0.46   0.21   0.54   3.335  2.335  1.165  2.415  2.79\n",
      "  4.625  1.04   6.75   1.875 16.    12.75   5.375  2.125 17.5    3.125\n",
      "  0.79   8.29 ]\n",
      "['t' 'f']\n",
      "['t' 'f']\n",
      "[ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n",
      "['g' 's' 'p']\n",
      "[     0    560    824      3  31285   1349    314   1442    200   2690\n",
      "    245   1208   1260     11  10000   5000   4000     35    713    551\n",
      "    500    300    221   2283    100     15    284   1236   5800    730\n",
      "    400  50000    456  15108   2954      2     20     27    225      1\n",
      "     38      5    130    147    210  11202   1332     50    258    567\n",
      "   1000   2510    809    610    150  51100    367    600    247    375\n",
      "    278    827   2072    582   2300   3065   2200      6   1602   2184\n",
      "   3376   2000   7544  10561    837  11177    639   2028   1065    540\n",
      "    158  15000   3000   3257   1655   1430      7    790    396    678\n",
      "   1187   6590    168   1270   1210    742   8851   7059   1704    857\n",
      "   6700   2503   9800    196     14  26726  18027     99    444   1200\n",
      "   2010     13    120     32    722     40    484    204     98   5552\n",
      "    105   2803    126      4     21    173     10     25     42 100000\n",
      "    113      8     44   2732    179     16   1062    251    228     67\n",
      "     12    122   4208   1300    112   1110   1004    286   4500   1212\n",
      "    195     87     17    184    140     18    146     22     55     70\n",
      "     60   1058    769   5200     19    316    350   3552    687   1950\n",
      "     53     41     33     80    351   2100    475    892   4607   2206\n",
      "   5860     28   1391   2279    591    960    690    234    800    990\n",
      "   2197     90    340    347    327   4071    109   1249    134   1344\n",
      "    321    948   2079   2384    458   5298    162   1583     58     59\n",
      "   1400   1465   8000   4700   1097   3290  13212   5777   5124     23\n",
      "   4159    918    768    283    108      9     68    587    141    501\n",
      "    160    390    154    117    246    237    364    537    394    750]\n",
      "['+' '-']\n"
     ]
    }
   ],
   "source": [
    "# EDA for missing values and feature categories\n",
    "\n",
    "# Better way to detect missing values\n",
    "columns = cc_apps.columns\n",
    "for column in columns:\n",
    "    print(cc_apps[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eaae6a2-e6e0-438d-bde4-4de1b3471920",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1717667975380,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Detecting missing values\ncc_apps_NaN = cc_apps.replace('?', np.NaN)\n\nprint(cc_apps_NaN.isna().sum().sort_values())",
    "outputsMetadata": {
     "0": {
      "height": 332,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "3      6\n",
      "4      6\n",
      "5      9\n",
      "6      9\n",
      "0     12\n",
      "1     12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detecting missing values\n",
    "cc_apps_NaN = cc_apps.replace('?', np.NaN)\n",
    "\n",
    "print(cc_apps_NaN.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a122b562-a7c4-4ea8-95f8-3f6b630a39be",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1717667975433,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "cc_apps_NaN[13] = np.where(cc_apps_NaN[13] == '+', 1,0)\ncc_apps_NaN[13].unique()"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_NaN[13] = np.where(cc_apps_NaN[13] == '+', 1,0)\n",
    "cc_apps_NaN[13].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ad82b2-a95e-4217-a631-888269131fad",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1717667975485,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Summary statistics for scaling\nprint(cc_apps_NaN.mean())\nprint('The discrepancy in the means of the numeric features showcases the need for scaling.')",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2        4.758725\n",
      "7        2.223406\n",
      "10       2.400000\n",
      "12    1017.385507\n",
      "13       0.444928\n",
      "dtype: float64\n",
      "The discrepancy in the means of the numeric features showcases the need for scaling.\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for scaling\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(cc_apps_NaN.mean())\n",
    "print('The discrepancy in the means of the numeric features showcases the need for scaling.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1644e746-54d1-4d84-a0d9-434e80df5e1b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 55,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1717667975540,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Approach 1: Not scale the binary one-hot-encoded categorical features \n\n# Further preprocessing\ncc_apps_NaN[1] = cc_apps_NaN[1].astype(float)\n\n# Make a copy\ncc_apps_NaN_copy = cc_apps_NaN.copy()\n\n# Split categorical and numerical values\ncat_columns = [0, 3, 4, 5, 6, 8, 9, 11]\nnum_columns = [1, 2, 7, 10, 12]\nX_cat = cc_apps_NaN[cat_columns].values\nX_num = cc_apps_NaN[num_columns].values\n# cc_apps_NaN[13] = np.where(cc_apps_NaN[13] == +, 1,0)\ny = cc_apps_NaN[13].values\n\n# Train-test split\nX_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size = 0.2, random_state = 69)\nX_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y, test_size = 0.2, random_state = 69)\n\n# Imputing with SimpleImputer for categorical data the median\nimp_cat = SimpleImputer(strategy = 'most_frequent')\nX_train_cat = imp_cat.fit_transform(X_train_cat)\nX_test_cat = imp_cat.transform(X_test_cat)\n\n# Imputing with SimpleImputer for numeric data the mean value\nimp_num = SimpleImputer()\nX_train_num = imp_num.fit_transform(X_train_num)\nX_test_num = imp_num.transform(X_test_num)\n\n# Scaling to minimize variation of statistic metrics between features\nscaler = StandardScaler()\nX_train_num_scaled = scaler.fit_transform(X_train_num)\nX_test_num_scaled = scaler.transform(X_test_num)\n\n# One-Hot encoding for the categorical features\nencoder = OneHotEncoder(drop='first', sparse=False)\nX_train_cat_enc = encoder.fit_transform(X_train_cat)\nX_test_cat_enc = encoder.transform(X_test_cat)\n\n# Appending all features together\nX_train = np.append(X_train_num_scaled, X_train_cat_enc, axis = 1)\nX_test = np.append(X_test_num_scaled, X_test_cat_enc, axis = 1)\n \n\n# Printing test and train sets\nprint('The training set after imputation and encoding and scaling is')\nprint(X_train)\nprint('\\nThe testing set after imputation and encoding and scaling is')\nprint(y_train)",
    "outputsMetadata": {
     "0": {
      "height": 555,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set after imputation and encoding and scaling is\n",
      "[[-0.2290986  -0.8784957  -0.55982857 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.27611934 -0.86142068 -0.5218726  ...  1.          0.\n",
      "   0.        ]\n",
      " [-1.19752614  3.46559083 -0.64788642 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-1.11950921  1.13836574 -0.60993045 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.92192285  1.10522011 -0.43229651 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.22289079 -0.35117884  1.60366179 ...  0.          0.\n",
      "   0.        ]]\n",
      "\n",
      "The testing set after imputation and encoding and scaling is\n",
      "[0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Approach 1: Not scale the binary one-hot-encoded categorical features \n",
    "\n",
    "# Further preprocessing\n",
    "cc_apps_NaN[1] = cc_apps_NaN[1].astype(float)\n",
    "\n",
    "# Make a copy\n",
    "cc_apps_NaN_copy = cc_apps_NaN.copy()\n",
    "\n",
    "# Split categorical and numerical values\n",
    "cat_columns = [0, 3, 4, 5, 6, 8, 9, 11]\n",
    "num_columns = [1, 2, 7, 10, 12]\n",
    "X_cat = cc_apps_NaN[cat_columns].values\n",
    "X_num = cc_apps_NaN[num_columns].values\n",
    "# cc_apps_NaN[13] = np.where(cc_apps_NaN[13] == +, 1,0)\n",
    "y = cc_apps_NaN[13].values\n",
    "\n",
    "# Train-test split\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size = 0.2, random_state = 69)\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y, test_size = 0.2, random_state = 69)\n",
    "\n",
    "# Imputing with SimpleImputer for categorical data the median\n",
    "imp_cat = SimpleImputer(strategy = 'most_frequent')\n",
    "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
    "X_test_cat = imp_cat.transform(X_test_cat)\n",
    "\n",
    "# Imputing with SimpleImputer for numeric data the mean value\n",
    "imp_num = SimpleImputer()\n",
    "X_train_num = imp_num.fit_transform(X_train_num)\n",
    "X_test_num = imp_num.transform(X_test_num)\n",
    "\n",
    "# Scaling to minimize variation of statistic metrics between features\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "\n",
    "# One-Hot encoding for the categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_cat_enc = encoder.fit_transform(X_train_cat)\n",
    "X_test_cat_enc = encoder.transform(X_test_cat)\n",
    "\n",
    "# Appending all features together\n",
    "X_train = np.append(X_train_num_scaled, X_train_cat_enc, axis = 1)\n",
    "X_test = np.append(X_test_num_scaled, X_test_cat_enc, axis = 1)\n",
    " \n",
    "\n",
    "# Printing test and train sets\n",
    "print('The training set after imputation and encoding and scaling is')\n",
    "print(X_train)\n",
    "print('\\nThe testing set after imputation and encoding and scaling is')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7735884b-8901-47b8-ab9b-2900f4e84791",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1700,
    "lastExecutedAt": 1717667977240,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Training Logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\n\n# Determine probabilities from the positive group\ny_pred_probs = logreg.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n\n# Plot the ROC Curve \nplt.plot([0,1], [0,1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Logistic Regression ROC Curve')\nplt.show()\n\n#Determine the best parameter\nprint('The AUC of the ROC equals to:', roc_auc_score(y_test, y_pred_probs))\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f\"The confusion matrix of our model reads: \\n {conf_matrix}\")\n\n# Compute accuracy\naccuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\nprint(f\"Model's Accuracy: {accuracy}\")",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     },
     "1": {
      "height": 122,
      "type": "stream"
     },
     "2": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of the ROC equals to: 0.9292247386759582\n",
      "The confusion matrix of our model reads: \n",
      " [[67 15]\n",
      " [ 6 50]]\n",
      "Model's Accuracy: 0.8478260869565217\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Determine probabilities from the positive group\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "# Plot the ROC Curve \n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "#Determine the best parameter\n",
    "print('The AUC of the ROC equals to:', roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f\"The confusion matrix of our model reads: \\n {conf_matrix}\")\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
    "print(f\"Model's Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edbbb1c6-d966-4148-9139-adcd1280a6cb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 233635,
    "lastExecutedAt": 1717668210876,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Hyperparameter tuning for logistic regression\nkf = KFold(n_splits = 6, shuffle = True, random_state = 69)\nparam_grid = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n              'C': np.linspace(0.001,1, 20),\n              'solver': ['lbfgs', 'liblinear', 'saga']\n             }\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=kf)\nlogreg_cv.fit(X_train, y_train)\nprint(logreg_cv.best_params_, logreg_cv.best_score_)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.3164736842105263, 'penalty': 'l1', 'solver': 'saga'} 0.8623188405797101\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for logistic regression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "kf = KFold(n_splits = 6, shuffle = True, random_state = 69)\n",
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "              'C': np.linspace(0.001,1, 20),\n",
    "              'solver': ['lbfgs', 'liblinear', 'saga']\n",
    "             }\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=kf)\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "print(logreg_cv.best_params_, logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86dff9ce-5de2-4c01-942d-aa2aafb12401",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2737,
    "lastExecutedAt": 1717668213614,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Hyperparameter tuning for KNN \n\nkf = KFold(n_splits = 6, random_state = 69, shuffle = True)\nparam_grid = {'n_neighbors':np.arange(1,100,1)}\nknn=KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, param_grid, cv = kf)\nknn_cv.fit(X_train, y_train)\n\nprint(knn_cv.best_params_, knn_cv.best_score_)",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13} 0.842391304347826\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for KNN \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "\n",
    "kf = KFold(n_splits = 6, random_state = 69, shuffle = True)\n",
    "param_grid = {'n_neighbors':np.arange(1,100,1)}\n",
    "knn=KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = kf)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "print(knn_cv.best_params_, knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8c2103a-9db8-4bbe-868b-34721d9b979a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 69629,
    "lastExecutedAt": 1717668491746,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Models comparison with GridSearchCV\nmodels = {\n    \"Logistic Regression\": (LogisticRegression(), {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n                                                   'C': np.linspace(0.001, 1, 5),\n                                                   'solver': ['lbfgs', 'liblinear', 'saga']}),\n    \"KNN\": (KNeighborsClassifier(), {'n_neighbors': np.arange(1, 50)}),\n    \"Decision Tree\": (DecisionTreeClassifier(), {'criterion': ['gini', 'entropy'],\n                                                 'max_depth': np.arange(1, 20)})\n}\n\nmodel_scores = {}\nresults = []\nkf = KFold(n_splits=6, random_state=69, shuffle=True)\n\nfor model_name, (model, param_grid) in models.items():\n    model_cv = GridSearchCV(model, param_grid, cv=kf)\n    model_cv.fit(X_train, y_train)\n    # Print the best parameters and scores for each model\n    print(f\"{model_name}: Best Params: {model_cv.best_params_}, Best Score: {model_cv.best_score_}\")\n    model_scores[model_name] =  model_cv.best_score_",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Best Params: {'C': 0.3164736842105263, 'penalty': 'l1', 'solver': 'saga'}, Best Score: 0.8623188405797101\n",
      "KNN: Best Params: {'n_neighbors': 13}, Best Score: 0.842391304347826\n",
      "Decision Tree: Best Params: {'criterion': 'gini', 'max_depth': 1}, Best Score: 0.8568840579710143\n"
     ]
    }
   ],
   "source": [
    "# Models comparison with GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(), {'penalty': ['l1', 'l2', 'elasticnet','none'],\n",
    "                                                   'C': np.linspace(0.001, 1, 20),\n",
    "                                                   'solver': ['lbfgs', 'liblinear', 'saga']}),\n",
    "    \"KNN\": (KNeighborsClassifier(), {'n_neighbors': np.arange(1, 50)}),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {'criterion': ['gini', 'entropy'],\n",
    "                                                 'max_depth': np.arange(1, 20)})\n",
    "}\n",
    "\n",
    "model_scores = {}\n",
    "results = []\n",
    "kf = KFold(n_splits=6, random_state=69, shuffle=True)\n",
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    model_cv = GridSearchCV(model, param_grid, cv=kf)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    # Print the best parameters and scores for each model\n",
    "    print(f\"{model_name}: Best Params: {model_cv.best_params_}, Best Score: {model_cv.best_score_}\")\n",
    "    model_scores[model_name] =  model_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57a8a1c5-454f-4be6-90b8-2774d57e24f0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1717668498515,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Finding the best score\n\nbest_model = max(model_scores, key=model_scores.get)\n\n# Get the maximum value (best score)\nbest_score = model_scores[best_model]\n\nprint(f'Best model:{best_model}')\nprint(f'Best Accuracy:{best_score}')",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:Logistic Regression\n",
      "Best Accuracy:0.8605072463768116\n"
     ]
    }
   ],
   "source": [
    "# Finding the best score\n",
    "best_model = max(model_scores, key=model_scores.get)\n",
    "\n",
    "# Get the maximum value (best score)\n",
    "best_score = model_scores[best_model]\n",
    "\n",
    "print(f'Best model:{best_model}')\n",
    "print(f'Best Accuracy:{best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "640f39e1-a153-42a3-8bcd-a53934a4ec9a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 22,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1717668507250,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Approach 2: Scale the binary one-hot-encoded categorical features \n\n# Train-test split\nX_train_cat1, X_test_cat1, y_train1, y_test1 = train_test_split(X_cat, y, test_size = 0.2, random_state = 69)\nX_train_num1, X_test_num1, y_train1, y_test1 = train_test_split(X_num, y, test_size = 0.2, random_state = 69)\n\n# Imputing with SimpleImputer for categorical data the median\nimp_cat = SimpleImputer(strategy = 'most_frequent')\nX_train_cat1 = imp_cat.fit_transform(X_train_cat1)\nX_test_cat1 = imp_cat.transform(X_test_cat1)\n\n# Imputing with SimpleImputer for numeric data the mean value\nimp_num = SimpleImputer()\nX_train_num1 = imp_num.fit_transform(X_train_num1)\nX_test_num1 = imp_num.transform(X_test_num1)\n\n# One-Hot encoding for the categorical features\nencoder = OneHotEncoder(drop='first', sparse=False)\nX_train_cat_enc1 = encoder.fit_transform(X_train_cat1)\nX_test_cat_enc1 = encoder.transform(X_test_cat1)\n\n# Appending all features together\nX_train1 = np.append(X_train_num1, X_train_cat_enc1, axis = 1)\nX_test1 = np.append(X_test_num1, X_test_cat_enc1, axis = 1)\n \n# Scaling to minimize variation of statistic metrics between features\nscaler = StandardScaler()\nX_train_scaled1 = scaler.fit_transform(X_train1)\nX_test_scaled1 = scaler.transform(X_test1)\n\n# Printing test and train sets\nprint('The training set after imputation and encoding and scaling is')\nprint(X_train_scaled1)\nprint('\\nThe testing set after imputation and encoding and scalingh is')\nprint(X_test_scaled1)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set after imputation and encoding and scaling is\n",
      "[[-0.2290986  -0.8784957  -0.55982857 ... -0.86100228 -0.12126781\n",
      "  -0.31211457]\n",
      " [ 1.27611934 -0.86142068 -0.5218726  ...  1.16143711 -0.12126781\n",
      "  -0.31211457]\n",
      " [-1.19752614  3.46559083 -0.64788642 ... -0.86100228  8.24621125\n",
      "  -0.31211457]\n",
      " ...\n",
      " [-1.11950921  1.13836574 -0.60993045 ... -0.86100228 -0.12126781\n",
      "  -0.31211457]\n",
      " [-0.92192285  1.10522011 -0.43229651 ...  1.16143711 -0.12126781\n",
      "  -0.31211457]\n",
      " [ 0.22289079 -0.35117884  1.60366179 ... -0.86100228 -0.12126781\n",
      "  -0.31211457]]\n",
      "\n",
      "The testing set after imputation and encoding and scalingh is\n",
      "[[-0.80913751 -0.78709411  0.009511   ... -0.86100228 -0.12126781\n",
      "  -0.31211457]\n",
      " [ 0.06007285 -0.45162014 -0.26832671 ... -0.86100228 -0.12126781\n",
      "  -0.31211457]\n",
      " [-1.31794357 -0.886531   -0.64788642 ...  1.16143711 -0.12126781\n",
      "  -0.31211457]\n",
      " ...\n",
      " [ 1.71369255 -0.54402615 -0.19241477 ... -0.86100228 -0.12126781\n",
      "  -0.31211457]\n",
      " [ 0.90129887 -0.6022821  -0.64788642 ... -0.86100228 -0.12126781\n",
      "  -0.31211457]\n",
      " [-0.08069683  1.45676469 -0.04059089 ...  1.16143711 -0.12126781\n",
      "  -0.31211457]]\n"
     ]
    }
   ],
   "source": [
    "# Approach 2: Scale the binary one-hot-encoded categorical features \n",
    "\n",
    "# Train-test split\n",
    "X_train_cat1, X_test_cat1, y_train1, y_test1 = train_test_split(X_cat, y, test_size = 0.2, random_state = 69)\n",
    "X_train_num1, X_test_num1, y_train1, y_test1 = train_test_split(X_num, y, test_size = 0.2, random_state = 69)\n",
    "\n",
    "# Imputing with SimpleImputer for categorical data the median\n",
    "imp_cat = SimpleImputer(strategy = 'most_frequent')\n",
    "X_train_cat1 = imp_cat.fit_transform(X_train_cat1)\n",
    "X_test_cat1 = imp_cat.transform(X_test_cat1)\n",
    "\n",
    "# Imputing with SimpleImputer for numeric data the mean value\n",
    "imp_num = SimpleImputer()\n",
    "X_train_num1 = imp_num.fit_transform(X_train_num1)\n",
    "X_test_num1 = imp_num.transform(X_test_num1)\n",
    "\n",
    "# One-Hot encoding for the categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_cat_enc1 = encoder.fit_transform(X_train_cat1)\n",
    "X_test_cat_enc1 = encoder.transform(X_test_cat1)\n",
    "\n",
    "# Appending all features together\n",
    "X_train1 = np.append(X_train_num1, X_train_cat_enc1, axis = 1)\n",
    "X_test1 = np.append(X_test_num1, X_test_cat_enc1, axis = 1)\n",
    " \n",
    "# Scaling to minimize variation of statistic metrics between features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled1 = scaler.fit_transform(X_train1)\n",
    "X_test_scaled1 = scaler.transform(X_test1)\n",
    "\n",
    "# Printing test and train sets\n",
    "print('The training set after imputation and encoding and scaling is')\n",
    "print(X_train_scaled1)\n",
    "print('\\nThe testing set after imputation and encoding and scalingh is')\n",
    "print(X_test_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fe1ff0c-81d5-48f1-b221-11a3247f39be",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 101169,
    "lastExecutedAt": 1717668695655,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "model_scores1 = {}\nresults1 = []\nkf = KFold(n_splits=6, random_state=69, shuffle=True)\n\nfor model_name, (model, param_grid) in models.items():\n    model_cv1 = GridSearchCV(model, param_grid, cv=kf)\n    model_cv1.fit(X_train1, y_train1)\n    # Print the best parameters and scores for each model\n    print(f\"{model_name}: Best Params: {model_cv1.best_params_}, Best Score: {model_cv1.best_score_}\")\n    model_scores1[model_name] =  model_cv1.best_score_",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Best Params: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}, Best Score: 0.8641304347826085\n",
      "KNN: Best Params: {'n_neighbors': 16}, Best Score: 0.7119565217391305\n",
      "Decision Tree: Best Params: {'criterion': 'gini', 'max_depth': 1}, Best Score: 0.8568840579710143\n"
     ]
    }
   ],
   "source": [
    "# Comparing models accuracies for scaled binary one-hot encoded features\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_scores1 = {}\n",
    "results1 = []\n",
    "kf = KFold(n_splits=6, random_state=69, shuffle=True)\n",
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    model_cv1 = GridSearchCV(model, param_grid, cv=kf)\n",
    "    model_cv1.fit(X_train1, y_train1)\n",
    "    # Print the best parameters and scores for each model\n",
    "    print(f\"{model_name}: Best Params: {model_cv1.best_params_}, Best Score: {model_cv1.best_score_}\")\n",
    "    model_scores1[model_name] =  model_cv1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ecc962-349e-4334-a256-cc86f5992b80",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1717668903109,
    "lastExecutedByKernel": "3f73bb14-b0f7-498f-9b40-07baa57c92ef",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Finding the best score\nbest_model1 = max(model_scores1, key=model_scores1.get)\n\n# Get the maximum value (best score)\nbest_score1 = model_scores1[best_model1]\n# Comparison of approaches\na = best_score1 > best_score\n\nprint(f'Best model:{best_model1}')\nprint(f'Best Accuracy:{best_score1}')\nprint(f'Approach 2 provides a higher accuracy than Approach 1: {a}!')",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:Logistic Regression\n",
      "Best Accuracy:0.8641304347826085\n",
      "Approach 2 provides a higher accuracy than Approach 1: True!\n"
     ]
    }
   ],
   "source": [
    "# Finding the best score\n",
    "best_model1 = max(model_scores1, key=model_scores1.get)\n",
    "\n",
    "# Get the maximum value (best score)\n",
    "best_score1 = model_scores1[best_model1]\n",
    "# Comparison of approaches\n",
    "a = best_score1 > best_score\n",
    "\n",
    "print(f'Best model:{best_model1}')\n",
    "print(f'Best Accuracy:{best_score1}')\n",
    "print(f'Approach 2 provides a higher accuracy than Approach 1: {a}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130e1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
